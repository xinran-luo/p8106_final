---
title: "P8106 Data Science II Final Project"
author: "Stephanie Zhen, Xinran Luo, Ran An"
date: "5/4/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r message=FALSE}
library(tidyverse)
library(readr)
library(Amelia)
library(DataExplorer)
library(caret)
library(pROC)
library(ROCR)
library(klaR)
library(AppliedPredictiveModeling)
library(naivebayes)
library(rpart.plot)
```

age: age in years

sex: (1 = male; 0 = female)

cp: chest pain type (typical angina, atypical angina, non-angina, or asymptomatic angina)

trestbps: resting blood pressure (in mm Hg on admission to the hospital)

chol: serum cholestoral in mg/dl

fbs: Fasting blood sugar (< 120 mg/dl or > 120 mg/dl) (1 = true; 0 = false)

restecg: resting electrocardiographic results (normal, ST-T wave abnormality, or left ventricular hypertrophy)

thalach: Max. heart rate achieved during thalium stress test

exang: Exercise induced angina (1 = yes; 0 = no)

oldpeak: ST depression induced by exercise relative to rest

slope: Slope of peak exercise ST segment (0 = upsloping, 1 = flat, or 2 = downsloping)

ca: number of major vessels (0-3) colored by flourosopy 4 = NA

thal: Thalium stress test result 3 = normal; 6 = fixed defect; 7 = reversable defect 0 = NA

target: Heart disease status 1 or 0 (0 = heart disease 1 = asymptomatic)

### Load the data

```{r message=FALSE}
heart = read_csv("./data/heart.csv")
head(heart)

summary(heart)

missmap(heart)
```


###Data Cleaning:
```{r}
heart_nomiss = heart %>%
  filter(thal != 0 & ca != 4) %>% 
  mutate(
    sex = case_when(
     sex == 1 ~ "male",
    sex == 0 ~ "female"
           ),
    fbs = case_when(
      fbs == 1 ~ "true",
      fbs == 0 ~ "false"
            ),
    exang = case_when(
      exang == 1 ~ "yes",
      exang == 0 ~ "no"
            ),
    cp = case_when(
      cp == 3 ~ "typical_angina",
      cp == 1 ~ "atypical_angina",
      cp == 2 ~ "non_anginal",
      cp == 0 ~ "asymptomatic_angina"
          ),
    restecg = case_when(
      restecg == 2 ~ "wave_abnormality",
      restecg == 1 ~ "normal",
      restecg == 0 ~ "hypertrophy"
              ),
    target = case_when(
      target == 1 ~ "asymptomatic",
      target == 0 ~ "heart_disease"
              ),
    slope = case_when(
      slope == 2 ~ "upsloping",
      slope == 1 ~ "flat",
      slope == 0 ~ "downsloping"
    ),
    thal = case_when(
      thal == 3 ~ "reversable_defect",
      thal == 2 ~ "normal",
      thal == 1 ~ "fixed_defect"
    ),
    sex = as.factor(sex),
    fbs = as.factor(fbs),
    exang = as.factor(exang),
    cp = as.factor(cp),
    slope = as.factor(slope),
    ca = as.factor(ca),
    thal = as.factor(thal)
  )
```


```{r}
plot_density(heart_nomiss)
```

```{r}
plot_bar(heart_nomiss)
```


```{r}
### Age vs outcome(target)
ggplot(data = heart_nomiss, aes(x = target, y = age)) + 
  geom_boxplot() +
  labs(x = "Heart Disease Status",
       y = "Age",
       title = "Heart Disease by Age")

### CP vs outcome(target)
#ggplot(data = heart_nomiss, aes(x = cp,
                                #fill = target)) + 
  #geom_bar(position = position_dodge())

### Gender vs outcome(target)
ggplot(data = heart_nomiss, aes(x = sex,
                                fill = target)) + 
  geom_bar(position = position_dodge()) + 
  labs(x = "Gender",
       y = "Count",
       title = "Heart Disease by Gender")
```


###Partition the data for training
```{r}
set.seed(1)
train.indices <- createDataPartition(y = heart_nomiss$target, p = 0.7, list = FALSE)

training <- heart_nomiss[train.indices,]
testing <- heart_nomiss[-train.indices,]
```


###Naive Bayes (NB)
```{r}
set.seed(1)

heart.nb = naive_bayes(as.factor(target) ~ ., data = training)
nb.pred <- predict(heart.nb, newdata = testing, type = "prob")[,2]
roc.nb <- roc(testing$target, nb.pred)
#ROC curve
plot(roc.nb)
roc.nb$auc
```


## rpart
```{r}
control = trainControl(method = "repeatedcv",
                        summaryFunction = twoClassSummary,
                        classProbs = TRUE)

set.seed(1)
rpart_fit = train(target ~ .,
                  data = training,
                  method = "rpart",
                  tuneGrid = data.frame(cp = exp(seq(-9, -5, len = 30))),
                  trControl = control,
                  metric = "ROC")

ggplot(rpart_fit, highlight = TRUE)
rpart.plot(rpart_fit$finalModel)

##Predict using train data
rpart_train = predict(rpart_fit,
                      newdata = training,
                      type = "prob")[,2]

roc_rpart_train = roc(training$target, rpart_train)
plot(roc_rpart_train, legacy.axes = TRUE, print.auc = TRUE)
plot(roc_rpart_train, add = TRUE, col = 3)


##Predict using test data
rpart_test = predict(rpart_fit,
                      newdata = testing,
                      type = "prob")[,2]

roc_rpart_test = roc(testing$target, rpart_test)
plot(roc_rpart_test, legacy.axes = TRUE, print.auc = TRUE)
plot(roc_rpart_test, add = TRUE, col = 3)

```

### Random Forest
```{r}
rf_grid = expand.grid(mtry = 3:7,
                      splitrule = "gini",
                      min.node.size = 3:7)
set.seed(1)
rf_fit = train(target ~., 
               data = training,
               method = "ranger",
               tuneGrid = rf_grid,
               metric = "ROC",
               importance = "permutation",
               trControl = control)

ggplot(rf_fit, highlight = TRUE)

##Predicting using training data
rf_train = predict(rf_fit,
                  newdata = training, 
                  type = "prob")[,2]

roc_rf_train = roc(training$target, rf_train)
plot(roc_rf_train, legacy.axes = TRUE, print.auc = TRUE)
plot(roc_rf_train, add = TRUE, col = 3)

##Predict using test data
rf_test = predict(rpart_fit,
                      newdata = testing,
                      type = "prob")[,2]

roc_rf_test = roc(testing$target, rf_test)
plot(roc_rf_test, legacy.axes = TRUE, print.auc = TRUE)
plot(roc_rf_test, add = TRUE, col = 3)

```


### Variable importance using random forest
```{r}
rf_imp = varImp(rf_fit)
plot(rf_imp)
```



### support vector classifier (linear kernel)
```{r}
control1 <- trainControl(method = "cv")
set.seed(1)
# fit model
svml.fit <- train(target ~ ., 
                  data = training, 
                  method = "svmLinear2",
                  preProcess = c("center", "scale"),
                  tuneGrid = data.frame(cost = exp(seq(-5,-1,len=50))),
                  trControl = control1)
# model output
svml.fit$finalModel
# best tunning parameter
svml.fit$bestTune
# Accuracy plot
ggplot(svml.fit, highlight = TRUE)
# training error rate
pred_train = predict(svml.fit)
mean(training$target != pred_train)
# test error rate
pred_test = predict(svml.fit, newdata = testing, type = "raw")
mean(testing$target != pred_test)
```

### support vector machine(radial kernel)
```{r}
svmr.grid <- expand.grid(C = exp(seq(-5,2,len=20)),
                         sigma = exp(seq(-8,-1,len=10)))
set.seed(1) 
# fit model
svmr.fit <- train(target ~ ., training,
                  method = "svmRadial",
                  preProcess = c("center", "scale"),
                  tuneGrid = svmr.grid,
                  trControl = control1)
# model output
svmr.fit$finalModel
# best tunning parameter
svmr.fit$bestTune
# Accuracy plot
ggplot(svmr.fit, highlight = TRUE)
# training error rate
pred_train2 = predict(svmr.fit)
mean(training$target != pred_train2)
# test error rate
pred_test2 = predict(svmr.fit, newdata = testing, type = "raw")
mean(testing$target != pred_test2)
```